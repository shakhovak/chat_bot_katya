{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучние кросс-энкодера\n",
    "\n",
    "Для переранижирования кандидатов я буду использовать обученную на классификацию bert-модель. Модель будет оценивать предложенных кандидатов, состоящих из контекста, вопроса и ответа на предмет того, является ли ответ продолжением контекста + ответа.\n",
    "\n",
    "Для ранжирования правильных ответов - буду выбирать уверенность модели в классификации.\n",
    "\n",
    "Ниже представлен код для обучения модели и сохранения ее на Hugging Face для использования в чат боте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import Trainer, TrainingArguments, set_seed\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import wandb\n",
    "from transformers import EvalPrediction\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ceec374d354b3993bf279729019e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'context', 'label', 'answer', 'combined'],\n",
       "        num_rows: 17436\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['question', 'context', 'label', 'answer', 'combined'],\n",
       "        num_rows: 4360\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"data/scripts_for_reranker.pkl\")\n",
    "df_train, df_valid = train_test_split(data, test_size=0.2)\n",
    "\n",
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_pandas(df_train.reset_index(drop=True)),\n",
    "        \"valid\": Dataset.from_pandas(df_valid.reset_index(drop=True)),\n",
    "    }\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 8773, 1: 8663})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        examples['combined'],\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCURACY = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    acc_result = ACCURACY.compute(predictions=preds, references=p.label_ids)\n",
    "    result = {\n",
    "        \"accuracy\": acc_result[\"accuracy\"],\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebaf3cf98c434a4c981ed9173c9a32d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17436 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5de35e4c8f848899fb10794ef6fa786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 17436\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4360\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_data, batched=True)\n",
    "encoded_dataset = encoded_dataset.remove_columns([\"context\", \"question\", \"answer\", \"combined\"])\n",
    "encoded_dataset = encoded_dataset.rename_column(\"label\", \"labels\")\n",
    "encoded_dataset.set_format(\"torch\")\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=2\n",
    ")\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"reranker_train\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkatya_shakhova\u001b[0m (\u001b[33mshakhova\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"RerankerModel_chat_bot\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.001,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=1,\n",
    "    group_by_length=True,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Kate\\chat_bot_katya\\wandb\\run-20240210_195246-dz09e4n6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shakhova/reranker_train/runs/dz09e4n6' target=\"_blank\">vibrant-cake-3</a></strong> to <a href='https://wandb.ai/shakhova/reranker_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shakhova/reranker_train' target=\"_blank\">https://wandb.ai/shakhova/reranker_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shakhova/reranker_train/runs/dz09e4n6' target=\"_blank\">https://wandb.ai/shakhova/reranker_train/runs/dz09e4n6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c420796f87486390d3df5c3f570a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6812, 'learning_rate': 3.822629969418961e-05, 'epoch': 0.23}\n",
      "{'loss': 0.6066, 'learning_rate': 4.957490420675732e-05, 'epoch': 0.46}\n",
      "{'loss': 0.5726, 'learning_rate': 4.7494362173553114e-05, 'epoch': 0.69}\n",
      "{'loss': 0.56, 'learning_rate': 4.38212672347195e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffbac4ad3e94f78b5d86accaf1beb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5250728726387024, 'eval_accuracy': 0.7254587155963302, 'eval_runtime': 16.6173, 'eval_samples_per_second': 262.377, 'eval_steps_per_second': 32.797, 'epoch': 1.0}\n",
      "{'loss': 0.4904, 'learning_rate': 3.881566668443446e-05, 'epoch': 1.15}\n",
      "{'loss': 0.4679, 'learning_rate': 3.2831946374551544e-05, 'epoch': 1.38}\n",
      "{'loss': 0.4406, 'learning_rate': 2.629374095149702e-05, 'epoch': 1.61}\n",
      "{'loss': 0.416, 'learning_rate': 1.9663941426082897e-05, 'epoch': 1.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fa065d9f7649f4be31eb73a2d686b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.516691267490387, 'eval_accuracy': 0.7612385321100917, 'eval_runtime': 18.6674, 'eval_samples_per_second': 233.562, 'eval_steps_per_second': 29.195, 'epoch': 2.0}\n",
      "{'loss': 0.3747, 'learning_rate': 1.3411923476378066e-05, 'epoch': 2.06}\n",
      "{'loss': 0.29, 'learning_rate': 7.980316649956704e-06, 'epoch': 2.29}\n",
      "{'loss': 0.2644, 'learning_rate': 3.7536671351888096e-06, 'epoch': 2.52}\n",
      "{'loss': 0.2795, 'learning_rate': 1.0312127105846947e-06, 'epoch': 2.75}\n",
      "{'loss': 0.2469, 'learning_rate': 5.697347762481653e-09, 'epoch': 2.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615389f41c5045d990f002b7550c6c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7941048741340637, 'eval_accuracy': 0.7814220183486239, 'eval_runtime': 18.8117, 'eval_samples_per_second': 231.77, 'eval_steps_per_second': 28.971, 'epoch': 3.0}\n",
      "{'train_runtime': 610.1069, 'train_samples_per_second': 85.736, 'train_steps_per_second': 10.719, 'train_loss': 0.43677769144740675, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6540, training_loss=0.43677769144740675, metrics={'train_runtime': 610.1069, 'train_samples_per_second': 85.736, 'train_steps_per_second': 10.719, 'train_loss': 0.43677769144740675, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"valid\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bcfd7c0c5849a79bdb1b9920292739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='418.577 MB of 418.577 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅█</td></tr><tr><td>eval/loss</td><td>▁▁█</td></tr><tr><td>eval/runtime</td><td>▁██</td></tr><tr><td>eval/samples_per_second</td><td>█▁▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▄▅▅▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▄▅▅▆▆▇▇███</td></tr><tr><td>train/learning_rate</td><td>▆██▇▆▆▅▄▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▆▅▅▄▄▃▂▁▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.78142</td></tr><tr><td>eval/loss</td><td>0.7941</td></tr><tr><td>eval/runtime</td><td>18.8117</td></tr><tr><td>eval/samples_per_second</td><td>231.77</td></tr><tr><td>eval/steps_per_second</td><td>28.971</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>6540</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2469</td></tr><tr><td>train/total_flos</td><td>2270683352193840.0</td></tr><tr><td>train/train_loss</td><td>0.43678</td></tr><tr><td>train/train_runtime</td><td>610.1069</td></tr><tr><td>train/train_samples_per_second</td><td>85.736</td></tr><tr><td>train/train_steps_per_second</td><td>10.719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vibrant-cake-3</strong> at: <a href='https://wandb.ai/shakhova/reranker_train/runs/dz09e4n6' target=\"_blank\">https://wandb.ai/shakhova/reranker_train/runs/dz09e4n6</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240210_195246-dz09e4n6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
